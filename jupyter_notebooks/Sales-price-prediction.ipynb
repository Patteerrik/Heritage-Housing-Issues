{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Evaluate the performance of the optimized Gradient Boosting and XGBRegressor models.\n",
    "* Analyze feature importance to understand which variables have the most influence on house prices.\n",
    "* Ensure that the chosen model meets the business requirement (R2 ≥ 0.75)\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* The prepared dataset (`HousePricesFeatures.csv`)\n",
    "* Libraries for machine learning and data handling, including:\n",
    "  - **pandas** for data manipulation.\n",
    "  - **sklearn** for machine learning and model training.\n",
    "  - **matplotlib** and **seaborn** for visualizations.\n",
    "  - **joblib** for saving and loading models.\n",
    "\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* The optimized XGBRegressor model is saved as: jupyter_notebooks/outputs/best_model/best_xgboost_model.pkl.\n",
    "* Visualization of feature importance.\n",
    "* Model evaluation metrics (MSE, R2).\n",
    "* Conclusions regarding the model's performance and usability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Heritage-Housing-Issues/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Heritage-Housing-Issues'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import dump \n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.621711</td>\n",
       "      <td>204.517915</td>\n",
       "      <td>198.284295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7.303622</td>\n",
       "      <td>177.329636</td>\n",
       "      <td>264.601145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.667292</td>\n",
       "      <td>222.579733</td>\n",
       "      <td>209.206786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.625993</td>\n",
       "      <td>232.664362</td>\n",
       "      <td>180.779930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7.885038</td>\n",
       "      <td>288.451992</td>\n",
       "      <td>246.150776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalePrice  OverallQual  GrLivArea  GarageArea  TotalBsmtSF\n",
       "0   208500.0            7   7.621711  204.517915   198.284295\n",
       "1   181500.0            6   7.303622  177.329636   264.601145\n",
       "2   223500.0            7   7.667292  222.579733   209.206786\n",
       "3   140000.0            7   7.625993  232.664362   180.779930\n",
       "4   250000.0            8   7.885038  288.451992   246.150776"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected = pd.read_csv(\"outputs/datasets/collection/HousePricesFeaturesSelected.csv\")\n",
    "df_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df_selected.drop('SalePrice', axis=1)\n",
    "y = np.log1p(df_selected['SalePrice'])  # Log-transform the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Gradient Boosting Regressor optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__max_depth=None, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=200; total time=   4.6s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=200; total time=   4.7s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=200; total time=   5.0s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=200; total time=   4.9s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=5, model__n_estimators=300; total time=   6.4s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=200; total time=   5.2s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=200; total time=   5.0s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=200; total time=   6.3s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=200; total time=   5.3s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=200; total time=   5.9s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=300; total time=   5.3s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=5, model__n_estimators=300; total time=   7.1s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=200; total time=   6.0s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=5, model__n_estimators=300; total time=   6.9s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=5, model__n_estimators=300; total time=   6.4s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=5, model__n_estimators=300; total time=   6.1s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=200; total time=   4.0s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=200; total time=   3.9s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=300; total time=   5.5s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=200; total time=   4.5s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=200; total time=   4.2s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=300; total time=   5.3s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=4, model__min_samples_split=2, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=200; total time=   4.2s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=300; total time=   5.5s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=300; total time=   5.6s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=4, model__min_samples_split=2, model__n_estimators=100; total time=   1.2s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=4, model__min_samples_split=2, model__n_estimators=100; total time=   1.5s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=10, model__n_estimators=300; total time=   5.7s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=10, model__n_estimators=300; total time=   5.9s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=10, model__n_estimators=300; total time=   6.0s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=4, model__min_samples_split=2, model__n_estimators=100; total time=   1.1s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=10, model__n_estimators=300; total time=   6.2s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=10, model__n_estimators=300; total time=   6.2s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=4, model__min_samples_split=2, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=   1.7s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=200; total time=   4.1s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=200; total time=   3.7s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=   1.5s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=200; total time=   4.2s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=200; total time=   4.2s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=200; total time=   3.9s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=300; total time=   7.3s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=   1.5s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=300; total time=   7.7s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=300; total time=   7.8s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=   2.0s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=300; total time=   8.0s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=300; total time=   8.5s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=300; total time=   8.5s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=300; total time=   8.6s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=300; total time=   9.1s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=300; total time=   8.7s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=4, model__min_samples_split=2, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=4, model__min_samples_split=2, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=300; total time=   9.4s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=4, model__min_samples_split=2, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=10, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=10, model__n_estimators=100; total time=   2.0s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=10, model__n_estimators=100; total time=   1.9s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=10, model__n_estimators=100; total time=   1.9s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=10, model__n_estimators=100; total time=   2.5s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=4, model__min_samples_split=2, model__n_estimators=100; total time=   3.0s\n",
      "[CV] END model__max_depth=None, model__min_samples_leaf=4, model__min_samples_split=2, model__n_estimators=100; total time=   3.8s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=300; total time=   5.4s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=300; total time=   6.0s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=300; total time=   5.9s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=300; total time=   6.4s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=300; total time=   5.7s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=2, model__min_samples_split=10, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=300; total time=   4.7s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=300; total time=   4.6s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=5, model__n_estimators=200; total time=   3.9s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=5, model__n_estimators=200; total time=   3.8s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=5, model__n_estimators=200; total time=   4.0s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=300; total time=   5.1s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=300; total time=   5.2s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=5, model__n_estimators=200; total time=   3.9s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=2, model__min_samples_split=10, model__n_estimators=100; total time=   1.0s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=4, model__min_samples_split=5, model__n_estimators=200; total time=   4.4s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=300; total time=   4.9s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=2, model__min_samples_split=10, model__n_estimators=100; total time=   1.1s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=2, model__min_samples_split=10, model__n_estimators=100; total time=   1.0s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=2, model__min_samples_split=10, model__n_estimators=100; total time=   0.9s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=200; total time=   3.7s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=200; total time=   3.8s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=200; total time=   3.3s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=200; total time=   3.0s\n",
      "[CV] END model__max_depth=30, model__min_samples_leaf=4, model__min_samples_split=10, model__n_estimators=200; total time=   3.1s\n",
      "Best hyperparameters from random search: {'model__n_estimators': 100, 'model__min_samples_split': 2, 'model__min_samples_leaf': 4, 'model__max_depth': 10}\n",
      "Optimized MSE: 953330178.3225563\n",
      "Optimized R2 Score: 0.8633824349482185\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('model', GradientBoostingRegressor(random_state=42))  # Model to train\n",
    "])\n",
    "\n",
    "# Define the parameters for randomized search\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [None, 10, 20, 30],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform randomized search for hyperparameters\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline, param_distributions=param_grid, n_iter=20, cv=5, n_jobs=-1, verbose=2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit the randomized search to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found and evaluate the model\n",
    "print(f\"Best hyperparameters from random search: {random_search.best_params_}\")\n",
    "\n",
    "# Evaluate the optimized model\n",
    "optimized_model = random_search.best_estimator_\n",
    "y_pred_optimized = optimized_model.predict(X_test)\n",
    "\n",
    "# Inverse log-transform predictions and target\n",
    "y_test_original = np.expm1(y_test)\n",
    "y_pred_original = np.expm1(y_pred_optimized)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_optimized = mean_squared_error(y_test_original, y_pred_original)\n",
    "r2_optimized = r2_score(y_test_original, y_pred_original)\n",
    "\n",
    "print(f\"Optimized MSE: {mse_optimized}\")\n",
    "print(f\"Optimized R2 Score: {r2_optimized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **XGBRegressor optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=100, model__subsample=1.0; total time=   0.5s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=100, model__subsample=1.0; total time=   0.4s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=100, model__subsample=1.0; total time=   1.4s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=100, model__subsample=1.0; total time=   1.5s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=100, model__subsample=1.0; total time=   1.4s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=100, model__subsample=1.0; total time=   1.5s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=100, model__subsample=1.0; total time=   1.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=100, model__subsample=1.0; total time=   0.4s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=100, model__subsample=1.0; total time=   0.4s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=100, model__subsample=1.0; total time=   0.4s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=10, model__n_estimators=200, model__subsample=0.8; total time=   1.5s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=10, model__n_estimators=200, model__subsample=0.8; total time=   1.5s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=10, model__n_estimators=200, model__subsample=0.8; total time=   1.4s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=10, model__n_estimators=200, model__subsample=0.8; total time=   1.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=10, model__n_estimators=300, model__subsample=0.8; total time=   3.4s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=10, model__n_estimators=200, model__subsample=0.8; total time=   1.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=20, model__n_estimators=100, model__subsample=0.8; total time=   1.5s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=10, model__n_estimators=300, model__subsample=0.8; total time=   3.4s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=10, model__n_estimators=300, model__subsample=0.8; total time=   3.5s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=10, model__n_estimators=300, model__subsample=0.8; total time=   3.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=10, model__n_estimators=300, model__subsample=0.8; total time=   4.3s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=20, model__n_estimators=100, model__subsample=0.8; total time=   1.3s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=20, model__n_estimators=100, model__subsample=0.8; total time=   1.2s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=20, model__n_estimators=100, model__subsample=0.8; total time=   1.5s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=20, model__n_estimators=100, model__subsample=0.8; total time=   1.3s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=30, model__n_estimators=200, model__subsample=1.0; total time=   5.1s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=30, model__n_estimators=200, model__subsample=1.0; total time=   5.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=100, model__subsample=0.8; total time=   2.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=100, model__subsample=0.8; total time=   2.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=30, model__n_estimators=200, model__subsample=1.0; total time=   5.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=30, model__n_estimators=200, model__subsample=1.0; total time=   5.5s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=30, model__n_estimators=200, model__subsample=1.0; total time=   5.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=100, model__subsample=0.8; total time=   2.3s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=100, model__subsample=0.8; total time=   2.4s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=300, model__subsample=1.0; total time=   2.2s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=100, model__subsample=0.8; total time=   2.3s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=30, model__n_estimators=100, model__subsample=0.8; total time=   1.8s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=None, model__n_estimators=200, model__subsample=1.0; total time=   0.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=None, model__n_estimators=200, model__subsample=1.0; total time=   0.7s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=300, model__subsample=1.0; total time=   2.2s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=100, model__subsample=0.8; total time=   1.2s[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=100, model__subsample=0.8; total time=   1.2s\n",
      "\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=300, model__subsample=1.0; total time=   2.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=None, model__n_estimators=200, model__subsample=1.0; total time=   0.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=300, model__subsample=1.0; total time=   2.5s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=100, model__subsample=0.8; total time=   1.4s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=100, model__subsample=0.8; total time=   1.3s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=30, model__n_estimators=100, model__subsample=0.8; total time=   2.0s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=100, model__subsample=0.8; total time=   1.2s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=None, model__n_estimators=200, model__subsample=1.0; total time=   0.7s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=None, model__n_estimators=200, model__subsample=1.0; total time=   0.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=30, model__n_estimators=100, model__subsample=0.8; total time=   2.1s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=30, model__n_estimators=100, model__subsample=0.8; total time=   1.9s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=300, model__subsample=1.0; total time=   3.3s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=30, model__n_estimators=100, model__subsample=0.8; total time=   2.2s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=10, model__n_estimators=100, model__subsample=0.8; total time=   1.1s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=10, model__n_estimators=100, model__subsample=0.8; total time=   1.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=10, model__n_estimators=100, model__subsample=0.8; total time=   1.1s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=10, model__n_estimators=100, model__subsample=0.8; total time=   1.1s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=10, model__n_estimators=100, model__subsample=0.8; total time=   1.2s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=300, model__subsample=0.8; total time=   0.9s[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=300, model__subsample=0.8; total time=   0.9s\n",
      "\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=300, model__subsample=0.8; total time=   0.9s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=300, model__subsample=0.8; total time=   1.1s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=300, model__subsample=0.8; total time=   1.1s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=200, model__subsample=1.0; total time=   0.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=100, model__subsample=1.0; total time=   2.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=100, model__subsample=1.0; total time=   2.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=100, model__subsample=1.0; total time=   3.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=100, model__subsample=1.0; total time=   2.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=100, model__subsample=1.0; total time=   2.9s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=200, model__subsample=1.0; total time=   0.7s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=200, model__subsample=1.0; total time=   0.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=200, model__subsample=1.0; total time=   0.7s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=None, model__n_estimators=200, model__subsample=1.0; total time=   0.7s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=300, model__subsample=0.8; total time=   2.9s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=300, model__subsample=0.8; total time=   2.7s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=300, model__subsample=0.8; total time=   2.8s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=300, model__subsample=0.8; total time=   3.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=None, model__n_estimators=300, model__subsample=1.0; total time=   1.1s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=20, model__n_estimators=300, model__subsample=0.8; total time=   3.1s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=None, model__n_estimators=300, model__subsample=1.0; total time=   1.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=None, model__n_estimators=300, model__subsample=1.0; total time=   1.1s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=None, model__n_estimators=300, model__subsample=1.0; total time=   1.0s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=30, model__n_estimators=200, model__subsample=1.0; total time=   2.3s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=None, model__n_estimators=100, model__subsample=1.0; total time=   0.4s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=30, model__n_estimators=200, model__subsample=1.0; total time=   2.3s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=None, model__n_estimators=100, model__subsample=1.0; total time=   0.5s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=300, model__subsample=0.8; total time=   5.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=None, model__n_estimators=100, model__subsample=1.0; total time=   0.4s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=None, model__n_estimators=100, model__subsample=1.0; total time=   0.4s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=30, model__n_estimators=200, model__subsample=1.0; total time=   2.2s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=None, model__n_estimators=300, model__subsample=1.0; total time=   0.9s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=300, model__subsample=0.8; total time=   5.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=30, model__n_estimators=200, model__subsample=1.0; total time=   2.2s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=None, model__n_estimators=100, model__subsample=1.0; total time=   0.3s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=30, model__n_estimators=200, model__subsample=1.0; total time=   2.2s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=300, model__subsample=0.8; total time=   5.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=300, model__subsample=0.8; total time=   5.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.01, model__max_depth=30, model__n_estimators=300, model__subsample=0.8; total time=   5.8s\n",
      "Best hyperparameters from random search: {'model__subsample': 0.8, 'model__n_estimators': 300, 'model__max_depth': 10, 'model__learning_rate': 0.01, 'model__colsample_bytree': 1.0}\n",
      "Optimized MSE: 1083823768.657638\n",
      "Optimized R2 Score: 0.8446819710671605\n",
      "Saving the best model: <class 'xgboost.sklearn.XGBRegressor'>\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('model', XGBRegressor(random_state=42))  # Model to train\n",
    "])\n",
    "\n",
    "# Define the parameters for randomized search\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [None, 10, 20, 30],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],  # Typical learning rates for XGBoost\n",
    "    'model__subsample': [0.8, 1.0],  # Subsample ratio\n",
    "    'model__colsample_bytree': [0.8, 1.0],  # Column subsample ratio\n",
    "}\n",
    "\n",
    "\n",
    "# Perform randomized search for hyperparameters\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline, param_distributions=param_grid, n_iter=20, cv=5, n_jobs=-1, verbose=2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit the randomized search to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found and evaluate the model\n",
    "print(f\"Best hyperparameters from random search: {random_search.best_params_}\")\n",
    "\n",
    "# Evaluate the optimized model\n",
    "optimized_model = random_search.best_estimator_\n",
    "y_pred_optimized = optimized_model.predict(X_test)\n",
    "\n",
    "# Inverse log-transform predictions and target\n",
    "y_test_original = np.expm1(y_test)\n",
    "y_pred_original = np.expm1(y_pred_optimized)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_optimized = mean_squared_error(y_test_original, y_pred_original)\n",
    "r2_optimized = r2_score(y_test_original, y_pred_original)\n",
    "\n",
    "print(f\"Optimized MSE: {mse_optimized}\")\n",
    "print(f\"Optimized R2 Score: {r2_optimized}\")\n",
    "\n",
    "\n",
    "xgb_model = optimized_model.named_steps['model']\n",
    "\n",
    "\n",
    "print(f\"Saving the best model: {type(xgb_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Conclusion:**\n",
    "\n",
    "Both models worked well, but **Gradient Boosting Regressor** performed slightly better than **XGBRegressor**.\n",
    "\n",
    "- **R² Score**:\n",
    "  - **Gradient Boosting: 0.863**\n",
    "  - **XGBRegressor: 0.845**\n",
    "\n",
    "  **Gradient Boosting** explains more of the variation in house prices.\n",
    "\n",
    "- **Mean Squared Error (MSE)**:\n",
    "  - **Gradient Boosting: 953,330,178**\n",
    "  - **XGBRegressor: 1,083,823,768**\n",
    "\n",
    "  **Gradient Boosting** has a lower error, which means its predictions are closer to the actual prices.\n",
    "\n",
    "#### **Decision**:\n",
    "Because **Gradient Boosting** performs better, it is chosen as the final model to predict house prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting model saved successfully.\n",
      "XGBoost model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Spara den optimerade Gradient Boosting-modellen\n",
    "dump(optimized_model, 'outputs/best_model/best_gradient_boosting_model.pkl')\n",
    "print(\"Gradient Boosting model saved successfully.\")\n",
    "\n",
    "# Spara XGBoost-modellen\n",
    "dump(xgb_model, 'outputs/best_model/best_xgboost_model.pkl')\n",
    "print(\"XGBoost model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Calculating Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature  Importance\n",
      "0  OverallQual    0.542791\n",
      "1    GrLivArea    0.188554\n",
      "3  TotalBsmtSF    0.143993\n",
      "2   GarageArea    0.069383\n"
     ]
    }
   ],
   "source": [
    "# Calculate permutation importance\n",
    "result = permutation_importance(optimized_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': result.importances_mean\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Check the DataFrame\n",
    "print(importance_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature  Importance\n",
      "0  OverallQual    0.542791\n",
      "1    GrLivArea    0.188554\n",
      "3  TotalBsmtSF    0.143993\n",
      "2   GarageArea    0.069383\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize permutation importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=importance_df, palette=\"viridis\", orient=\"h\", hue='Feature')\n",
    "plt.title(\"Impact of Features on Model Performance\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "\n",
    "# Set the x-axis to start at 0\n",
    "plt.xlim(left=0)\n",
    "\n",
    "# Display the importance dataframe\n",
    "print(importance_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Importance Analysis**\n",
    "- **OverallQual** is the most important feature and has the biggest impact on the model’s performance. This means that the overall quality of a house is a key factor in determining its price. For real estate developers or sellers, this suggests that improving the house's quality can lead to higher prices.\n",
    "\n",
    "- **GrLivArea (living area)** and **BsmtFinSF1 (finished basement area)** are also important for pricing. Larger living spaces and more usable basement areas usually result in higher house prices. This is useful for builders and sellers to know that increasing house size or usable space can increase value.\n",
    "\n",
    "- Features like **GarageArea** and **2ndFlrSF (second floor area)** have smaller, but still important, effects on the model’s predictions. While these features are not as critical as the others, they still influence pricing, showing that buyers may care about having more garage space or a second floor, which could increase the house price if there is one..\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
